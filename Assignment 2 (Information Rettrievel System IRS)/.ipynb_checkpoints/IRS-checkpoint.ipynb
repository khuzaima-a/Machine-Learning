{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 IRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information retrieval is the process of obtaining information system resources that are relevant to an information need from a collection of those resources. The core purpose of this assignment is to give you the flavor of IRS. You need to follow some steps listed below and in the end, you'll be able to build your own small IRS. So, let's start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have 3 files containing data :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"This is my book\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f1.png?raw=true)\n",
    "![\"This is my pen\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f2.png?raw=true)\n",
    "![\"This is book is intersting\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Create Files with Dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to create few files with dummy data of your own choice as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = open(\"file1.txt\", \"w\") #Opened file in writing mode\n",
    "f1.write(\"This is my book\") #Wrote some content in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2 = open(\"file2.txt\", \"w\") #Opened file in writing mode\n",
    "f2.write(\"This is my pen\") #Wrote some content in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f3 = open(\"file3.txt\", \"w\") #Opened file in writing mode\n",
    "f3.write(\"My book is interesting\") #Wrote some content in the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Traverse Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, You have to traverse the directories and store all the files into a dict type variable(files_dict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have intialized some variables, you can add more if required.\n",
    "\n",
    "file_count = 0             # file_count to count number of files\n",
    "files_dict = {}            # files_dic to store count of every file    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is my book', 'This is my pen', 'My book is interesting']\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here   \n",
    "contents = []   #contents of all the files\n",
    "\n",
    "for filename in os.listdir():  #Checking all the files in the current directory\n",
    "    if filename[-4:] == '.txt':   # Searching for a file whose name end with '.txt'\n",
    "        file_count += 1         # Increment the file_count if '.txt' file is found.\n",
    "        file = open(filename)   # Opening that txt file\n",
    "        content = file.read()   # copying data of file to content variable\n",
    "        files_dict[filename] = len(content) # Storing count of chars of each txt file in files_dict\n",
    "        \n",
    "        contents.append(content)  # Adding the content of that file to contents array\n",
    "print(contents)                 # Printing contents\n",
    "\n",
    "#Your code ends here       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the count of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number  of files\n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTotal Number  of files\\n\", file_count) # Printing File_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Dictionary containing all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dictionary containing  files\n",
      " {'file1.txt': 15, 'file2.txt': 14, 'file3.txt': 22}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDictionary containing  files\\n\", files_dict) # Printing files_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 Extract Unique Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code to print all the unique words in every file and store them in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pen', 'My', 'my', 'This', 'book', 'is', 'interesting'}\n",
      "count of file  3\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here \n",
    "\n",
    "unique_word_set = set()    # unique_word_set to store all the unique words in a set\n",
    "\n",
    "for content in contents:   # Looping through content of each file\n",
    "    words = content.split()   # Spliting them into words\n",
    "    for word in words:      # Looping through each word\n",
    "#         print(word)\n",
    "        unique_word_set.add(word)   # Adding word to unique_word_set that is a set, no duplicates\n",
    "print(unique_word_set)      # Printing unique_word_set\n",
    "\n",
    "print(\"count of file \",file_count)\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o1.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Create Term Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Term-Doc-matrix using Bag of word approach.and display its contents initially and finally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Term doc matrix such that colmns will be unique words and all the files will be rows\n",
    "# Write code to count all the unique words appearances in all the files and store it in a dictionary for words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "dictionary of unique words\n",
      " {'pen': 0, 'My': 1, 'my': 2, 'This': 3, 'book': 4, 'is': 5, 'interesting': 6}\n",
      "\n",
      "dictionary of files\n",
      " {'file1.txt': 0, 'file2.txt': 1, 'file3.txt': 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here \n",
    "\n",
    "unique_words_count = {}     # Counting number of appearances of each word\n",
    "unique_word_id = {}        # Giving an id to each unique word\n",
    "file_id = {}               # Giving id to each file\n",
    "\n",
    "for word in words:        # Looping through each word\n",
    "    if word not in unique_words_count:  # Checking if word is not present in unique_Word_count\n",
    "        unique_words_count[word] = 1     # Adding it to it\n",
    "    else:                             # if already present\n",
    "        unique_words_count[word] += 1   # increment count\n",
    "        \n",
    "word_id = 0                  # id for words variable\n",
    "for word in unique_word_set:   # Looping though each unique word\n",
    "    unique_word_id[word] = word_id    # Giving it an id\n",
    "    word_id += 1                     # Incrementing id \n",
    "\n",
    "file_number = 0                       # id for file variable\n",
    "for file in files_dict:              # Looping through each file\n",
    "    file_id[file] = file_number        # Giving it file id \n",
    "    file_number += 1                 # Incrementing file id\n",
    "        \n",
    "        \n",
    "term_doc_matrix = np.zeros((file_count, len(unique_word_set)))   # Creating a Term_doc_matrix of \n",
    "                                                #(rows = number of files) and (cols = no. of unique words)\n",
    "                                                                                        \n",
    "print(term_doc_matrix, end='\\n\\n')  \n",
    "print(\"dictionary of unique words\\n\",unique_word_id, end='\\n\\n')\n",
    "print('dictionary of files\\n',file_id, end='\\n\\n')   \n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 Fill Term Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the term doc matrix by checking if the unique word exists in a file or not\n",
    "# If it exists then substitute a 1 in term_doc_matrix (eg : TERM_DOC_MATRIX[file][word] = 1 ) \n",
    "# Do the same for all the files present in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary of unique words\n",
      " {'pen': 0, 'My': 1, 'my': 2, 'This': 3, 'book': 4, 'is': 5, 'interesting': 6}\n",
      "\n",
      "[[0. 0. 1. 1. 1. 1. 0.]\n",
      " [1. 0. 1. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "\n",
    "print(\"dictionary of unique words\\n\",unique_word_id, end='\\n\\n')\n",
    "file_no = 0                    # File_no variable\n",
    "for content in contents:       # Looping though content of each file\n",
    "    words = content.split()    # Spliting the content into words\n",
    "    for word in words:         # for each word now\n",
    "        word_id = unique_word_id.get(word)  # Retrieve the word_id you gave it\n",
    "        if word in unique_word_set:    # If word is present in unique_word_set\n",
    "            term_doc_matrix[file_no][word_id] = 1   # Write 1 in line of that file_no and that word id from up\n",
    "    \n",
    "    file_no += 1  # Increment file_no\n",
    "    \n",
    "\n",
    "print(term_doc_matrix)\n",
    "\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o4.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 Ask for a user Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For user query make a column vector of length of all the unique words present in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "\n",
    "col_vector = np.zeros((len(unique_word_set),1))    # Create a column vector of (rows = no. of unique words)\n",
    "                                                # and (cols = 1)\n",
    "print(col_vector)\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o5.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Write something for searching  book is interesting\n"
     ]
    }
   ],
   "source": [
    "query = input(\"\\nWrite something for searching  \")\n",
    "# Check every word of query if it exists in the set of unique words or not\n",
    "# If exixts then increment the count of that word in word dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here \n",
    "\n",
    "q_words = query.split()    # Spliting the words of each querry\n",
    "for word in q_words:        # for each word \n",
    "    if word in unique_word_set:     # check if word present in unique_word_set\n",
    "        word_id = unique_word_id.get(word)    # retrive word id you gave it\n",
    "        col_vector[word_id][0] = 1       # Write 1 in front of that word in col_vector\n",
    "print(col_vector)\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o6.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 Display Resultant Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display \n",
    "1. Resultant vector.\n",
    "2. Max value in resultant vector.\n",
    "3. Index of max value in resultant vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n",
      " [[2.]\n",
      " [1.]\n",
      " [3.]]\n",
      "max_index 2\n",
      "max_value [3.]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "\n",
    "res_vector = np.dot(term_doc_matrix, col_vector)      # Creating a resultant vector from term_doc_matrix and col_vector\n",
    "max_index = np.argmax(res_vector)                     # Retrieve the max index \n",
    "max_value = max(res_vector)                           # Retreuve the max value\n",
    "\n",
    "print('result\\n',res_vector)\n",
    "print('max_index',max_index)\n",
    "print('max_value',max_value)\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o7.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 Display the contents of file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the code to identify the file_name having maximum value in the resultant vector and display its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Matching File Index 2\n",
      "\n",
      "file3.txt\n",
      "\n",
      "My book is interesting\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here   \n",
    "\n",
    "print('Most Matching File Index',max_index, end='\\n\\n')\n",
    "for file_name, index in file_id.items():\n",
    "    if index == max_index:\n",
    "        res_file = file_name\n",
    "        break\n",
    "print(res_file, end='\\n\\n')   # Print res vector\n",
    "f = open(res_file)     \n",
    "print(f.read())             # Print the content of file that matches most\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations Now you are able to build your own small IRS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
